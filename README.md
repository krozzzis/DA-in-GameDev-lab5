# Анализ данных в разработке игр
Отчет по лабораторной работе #5 выполнил:
- Шумов Никита Артёмович
- РИ-232702

## Отметка о выполнении заданий
| Задание   | Выполнение | Баллы |
| --------- | ---------- | ----- |
| Задание 1 | *          | 60    |
| Задание 2 | *          | 20    |
| Задание 3 | *          | 20    |

Знак "*" - задание выполнено; знак "#" - задание не выполнено;

## Работу проверили
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

## Структура отчета
- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Задание 2.
- Задание 3.
- Выводы.

## Цель работы
Познакомиться с программными средствами для создания системы машинного обучения и ее интеграции в Unity.

## Задание 1
Найдите внутри C# скрипта “коэффициент корреляции ” и сделать выводы о том, как он влияет на обучение модели.

---

Найдено значение 1.42

```c#
if(distanceToTarget < 1.42f)
```

Его оптимальная настройка влияет на то, как быстро и эффективно агент обучается стратегии достижения цели.

Если значение слишком большая, агенту будет проще достичь цели, но модель может не научиться точному управлению, так как достаточно приблизиться к цели, не обязательно оптимальным образом.

Если значение успеха слишком маленькая, агенту будет сложно завершать эпизоды, что может привести к замедлению обучения, особенно на ранних этапах, когда стратегия агента еще не сформирована.

## Задание 2
Изменить параметры файла yaml-агента и определить какие параметры и как влияют на обучение модели. Привести описание не менее трех параметров.  

---

- `learning_rate` — задает скорость обучения модели, влияя на то, насколько быстро модель адаптируется к изменениям.
- `num_epoch` — указывает количество итераций (эпох), в течение которых модель проходит обучение.
- `max_steps` — максимальное количество шагов, после которого обучение завершается.
- `summary_freq` — частота (в шагах), с которой создается отчет о текущем состоянии обучения.

Эти параметры играют ключевую роль в процессе обучения модели и должны подбираться в зависимости от специфики задачи.

## Задание 3
Привести примеры, для каких игровых задачи и ситуаций могут использоваться примеры 1 и 2 с ML-Agent’ом. Ответить на вопрос, в каких случаях проще использовать ML-агент, а не писать программную реализацию решения?  

--- 

1. **Пример 1**: *Поиск объектом на сцене*.  
ML-агенты могут быть использованы в играх, где NPC или враги должны искать игрока или объекты, адаптируясь к изменяющемуся окружению. Например:  
   - **Dead by Daylight** — враги, обученные искать игроков, реагируют на изменения в окружении.  
   - **Hunt: Showdown** — AI-монстры отслеживают игроков, учитывая их перемещения и укрытия.  
   - **Pac-Man** — призраки адаптируются к действиям игрока, преследуя его по меняющейся карте.

2. **Пример 2**: *Симулятор добычи ресурсов*.  
В играх с динамично изменяющимся окружением ML-агенты помогают NPC или дронам собирать ресурсы и адаптироваться к изменениям. Примеры:  
   - **Factorio** — дроны, оптимизирующие маршруты сбора ресурсов.  
   - **Satisfactory** — роботы, адаптирующиеся к изменениям в ландшафте.  
   - **Age of Empires** — крестьяне, меняющие маршруты сбора ресурсов в зависимости от изменений на карте.

ML-агенты удобны в играх с динамическим окружением и множеством переменных. Они эффективны, когда традиционные алгоритмы сложны или трудоемки, например, когда NPC должны адаптироваться к изменениям в ландшафте, взаимодействовать с другими игроками или реагировать на сложные паттерны. Это особенно актуально в играх с открытым миром, градостроительстве и стратегиях, где требуется гибкость и оптимизация поведения.

ML-агенты упрощают создание адаптивных NPC, которые могут реагировать на изменения в игре, улучшая взаимодействие с игроком и создавая более динамичные игровые миры.

## Выводы

В ходе работы я изучил средства для создания систем машинного обучения и их интеграции в Unity, освоил подключение ML-агента через AnacondaPrompt. Разобрался в конфигурации ML-агента и обучил две модели: поиск движущейся цели и сбор золота NPC-персонажем. Исследовал влияние параметров обучения на результаты, получив практические навыки настройки и анализа эффективности моделей.
